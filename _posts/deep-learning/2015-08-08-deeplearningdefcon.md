---
layout: note
title: Defcon Deep Learning Talk
date: 2015-08-15 20:14:44 -0600
categories: Deep-Learning
---

Notes on a skytalk given during Defcon.

- Zero sum game
	- Minimize loss
- Richard bellman (?)
- Overfitting: Training to the data too much
- John Nash
	- Father of game theory
- Nash Equilibrium : If every player has a strategy and if no player can change their strategy and do better they are at equilibrium
- Game theory can''t be applied to infosec
	1. Limited examples
	2. Multiple and Simultaneous (not rounds of play)
	3. No time constraints
	4. Different goals
	5. Legal (not government) moves change
	6. Goals change
	7. Update uncertainty (can''t deal with out of order punishments/rewards)
- Non convex optimization

# Deep Learning

Problems with deep learning and security:

- Complicated data types
- High dimensionality
- Expensive
- Dynamic
- Stochastic


- CRISP-DM
- Requires a lot of data, small datasets have better methods
- Trial and error
- Deep mind
	- Reinforcement learning works if you can gameify
- ALE - Arcade learning environment
- De-noising autoencoder : funelling multiple models into simpler ones


1. Gamify
2. AI like a boss
3. Mortal Kombat

Py vs Py : A framework for learning security games
- Looking for help
